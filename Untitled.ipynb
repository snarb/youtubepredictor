{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "from Constants import *\n",
    "from tensorflow.contrib.learn.python.learn.estimators import constants\n",
    "from tensorflow.contrib.learn.python.learn.estimators.dynamic_rnn_estimator import PredictionType\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.contrib.layers import real_valued_column\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import floor\n",
    "import matplotlib.mlab as mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 8 # Weeks count that is used to predict\n",
    "PREDICTION_DELTA = 4 # Weeks to predict ahead\n",
    "VIEWS_SCALE_KOEF = 18\n",
    "\n",
    "FILE_NAME = \"_s:{}_p:{}\".format(SEQUENCE_LENGTH, PREDICTION_DELTA)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "def LoadData(name):\n",
    "    all_training_data = np.load('data/' + name + FILE_NAME + \"_training_data.npy\" )\n",
    "    all_lables = np.load('data/' + name + FILE_NAME + \"_lables.npy\")\n",
    "    sta = np.vstack(all_training_data)\n",
    "    \n",
    "    df = pd.DataFrame(sta, columns=['channel_subscribers', 'views', 'engagements', 'sentiment'])\n",
    "    df[df < 0] = 0\n",
    "    df[df.views == 0] = 1\n",
    "    df[df.channel_subscribers == 0] = 1\n",
    "    all_lables[all_lables == 0] = 1\n",
    "\n",
    "    viewsKoef = floor(np.log(df.max()['views']))\n",
    "    df['views'] = np.log(df['views']) / viewsKoef\n",
    "    all_lables = np.log(all_lables) / viewsKoef\n",
    "    df['channel_subscribers'] = np.log(df['channel_subscribers']) / floor(np.log(df.max()['channel_subscribers']))\n",
    "    df[df.engagements > 1] = 1\n",
    "    df[df.sentiment > 1] = 1\n",
    "\n",
    "    all_training_data = df.values\n",
    "    columnsCount = np.size(all_training_data, 1)\n",
    "    inputs = np.reshape(all_training_data, (-1, BATCH_SIZE, SEQUENCE_LENGTH, columnsCount))\n",
    "    output = np.reshape(all_lables, (-1, BATCH_SIZE))\n",
    "\n",
    "    return inputs, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BuildModel(num_units, cell_type, optimizer, learning_rate):\n",
    "    \n",
    "    test_inputs, test_outputs = LoadData(\"TEST\")\n",
    "    columnsCount =  np.size(test_inputs, 3)\n",
    "\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension = columnsCount)]\n",
    "    estimator = tf.contrib.learn.DynamicRnnEstimator(problem_type = constants.ProblemType.LINEAR_REGRESSION,\n",
    "                                                     prediction_type = PredictionType.SINGLE_VALUE,\n",
    "                                                     sequence_feature_columns = feature_columns,\n",
    "                                                     context_feature_columns = None,\n",
    "                                                     num_units = num_units,\n",
    "                                                     cell_type = cell_type, #contrib_rnn.lstm\n",
    "                                                     optimizer = optimizer,\n",
    "                                                     learning_rate = learning_rate,\n",
    "                                                     gradient_clipping_norm=5.0,\n",
    "                                                     model_dir = \"models2/\")\n",
    "\n",
    "    def get_test_inputs():\n",
    "        inp = tf.constant(test_inputs)\n",
    "        target = tf.constant(test_outputs)\n",
    "        return {\"\": inp}, target\n",
    "\n",
    "    loss_score = estimator.evaluate(input_fn=get_test_inputs, steps=1)[\"loss\"]\n",
    "\n",
    "    print(\"\\nTest loss: {0:f}\\n\".format(loss_score))\n",
    "\n",
    "    predictions = list(estimator.predict({\"\" : test_inputs}))\n",
    "\n",
    "    predicted = [prediction['scores'] for prediction in predictions]  \n",
    "    \n",
    "    return (predicted, test_outputs, test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.000327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted, test_outputs, test_inputs = BuildModel(16, 'lstm', 'RMSProp', 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original RSE stats. Mean: 0.215, Std: 5.091\n",
      "Original MAPE stats. Mean: 18.13%, Std: 42.69% \n"
     ]
    }
   ],
   "source": [
    "originalPredicted = np.exp(np.array(predicted) * VIEWS_SCALE_KOEF)\n",
    "originalTestOutputs = np.exp(test_outputs * VIEWS_SCALE_KOEF)\n",
    "\n",
    "originalTestOutputs = np.concatenate(originalTestOutputs, axis=0)\n",
    "\n",
    "rse = ((originalPredicted / originalTestOutputs) - 1)**2\n",
    "mapeAr = abs(originalTestOutputs - originalPredicted) / originalTestOutputs\n",
    "\n",
    "\n",
    "print(\"Original RSE stats. Mean: %.3f, Std: %.3f\" % (rse.mean(), sqrt(rse.std())))\n",
    "\n",
    "print(\"Original MAPE stats. Mean: %.2f%%, Std: %.2f%% \" % (100 * mapeAr.mean(), 100 * mapeAr.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21514609728384487"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakeLastValuePrediction(inputs):\n",
    "    prediction = []\n",
    "    for input in inputs:\n",
    "        lasViews = input[0][7][1]\n",
    "        prediction.append(lasViews)\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakePolifitPrediction(inputs, n):\n",
    "    prediction = []\n",
    "    for input in inputs:\n",
    "        seq = input[0]\n",
    "        y = seq[:,1]\n",
    "        x = np.arange(8)\n",
    "\n",
    "        # calculate polynomial\n",
    "        z = np.polyfit(x, y, n)\n",
    "        f = np.poly1d(z)\n",
    "\n",
    "        pred = f(8)\n",
    "        prediction.append(pred)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last value prediction calculation\n",
      "Linear aproximation calculation\n",
      "Quadratic aproximation calculation\n",
      "Cubic aproximation calculation\n",
      "Calculation finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Last value prediction calculation\")\n",
    "lastValPreds = MakeLastValuePrediction(test_inputs)\n",
    "print(\"Linear aproximation calculation\")\n",
    "polPreds_1 = MakePolifitPrediction(test_inputs, 1)\n",
    "print(\"Quadratic aproximation calculation\")\n",
    "polPreds_2 = MakePolifitPrediction(test_inputs, 2)\n",
    "print(\"Cubic aproximation calculation\")\n",
    "polPreds_3 = MakePolifitPrediction(test_inputs, 3)\n",
    "print(\"Calculation finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last value prediction perfomance: 0.28%\n",
      "Linear perfomance: 0.23% Quadratic perfomance:0.03% Cubic perfomance:0.0002% \n"
     ]
    }
   ],
   "source": [
    "originalLastValPredicted = np.exp(np.array(lastValPreds) * VIEWS_SCALE_KOEF)\n",
    "\n",
    "originalPol1Predicted = np.exp(np.array(polPreds_1) * VIEWS_SCALE_KOEF)\n",
    "originalPol2Predicted = np.exp(np.array(polPreds_2) * VIEWS_SCALE_KOEF)\n",
    "originalPol3Predicted = np.exp(np.array(polPreds_3) * VIEWS_SCALE_KOEF)\n",
    "\n",
    "lastValEr = sqrt(mean_squared_error(originalLastValPredicted, test_outputs))\n",
    "Pol1Er = sqrt(mean_squared_error(originalPol1Predicted, test_outputs))\n",
    "Pol2Er = sqrt(mean_squared_error(originalPol2Predicted, test_outputs))\n",
    "Pol3Er = sqrt(mean_squared_error(originalPol3Predicted, test_outputs))\n",
    "\n",
    "print(\"Last value prediction perfomance: %.2f%%\" % (rnnRMSE / lastValEr))\n",
    "print(\"Linear perfomance: %.2f%% Quadratic perfomance:%.2f%% Cubic perfomance:%.4f%% \" % (rnnRMSE / Pol1Er, rnnRMSE / Pol2Er, rnnRMSE / Pol3Er) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
